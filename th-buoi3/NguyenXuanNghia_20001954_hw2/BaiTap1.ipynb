{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import *\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading CSV file\n",
    "data = read_csv(\"Admission_Predict.csv\")\n",
    "np.random.seed(1000)\n",
    "# converting column data to list, then convert list to array\n",
    "sn = data['Serial No.'].tolist()\n",
    "\n",
    "gre = data['GRE Score'].tolist()\n",
    "gre = [sc/100 for sc in gre]\n",
    "X1 = np.asarray(gre)\n",
    "\n",
    "tfl = data['TOEFL Score'].tolist()\n",
    "tfl = [sc/100 for sc in tfl]\n",
    "X2 = np.asarray(tfl)\n",
    "\n",
    "unirt = data['University Rating'].tolist()\n",
    "X3 = np.asarray(unirt)\n",
    "\n",
    "sop = data['SOP'].tolist()\n",
    "X4 = np.asarray(sop)\n",
    "\n",
    "lor1 = data['LOR '].tolist()\n",
    "X5 = np.asarray(lor1)\n",
    "\n",
    "cgpa1 = data['CGPA'].tolist()\n",
    "X6 = np.asarray(cgpa1)\n",
    "\n",
    "research_exp = data['Research'].tolist()\n",
    "X7 = np.asarray(research_exp)\n",
    "\n",
    "prob_Admit = data['Chance of Admit'].tolist()\n",
    "Yt = np.asarray(prob_Admit)\n",
    "# printing list data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(s):\n",
    "    return 1/(1 + np.exp(-s))\n",
    "\n",
    "def logistic_sigmoid_regression(X, y, w_init, eta, tol = 1e-4, max_count = 10000):\n",
    "    # method to calculate model logistic regression by Stochastic Gradient Descent method\n",
    "    # eta: learning rate; tol: tolerance; max_count: maximum iterates\n",
    "    w = [w_init]\n",
    "    it = 0\n",
    "    N = X.shape[1]\n",
    "    d = X.shape[0]\n",
    "    count = 0\n",
    "    check_w_after = 20\n",
    "    # loop of stochastic gradient descent\n",
    "    while count < max_count:\n",
    "        # shuffle the order of data (for stochastic gradient descent).\n",
    "        # and put into mix_id\n",
    "        mix_id = np.random.permutation(N)\n",
    "        for i in mix_id:\n",
    "            xi = X[:, i].reshape(d, 1)\n",
    "            yi = y[i]\n",
    "            zi = sigmoid(np.dot(w[-1].T, xi))\n",
    "            w_new = w[-1] + eta*(yi - zi)*xi\n",
    "            count += 1\n",
    "            # stopping criteria\n",
    "            if count%check_w_after == 0:\n",
    "                if np.linalg.norm(w_new - w[-check_w_after]) < tol:\n",
    "                    return w\n",
    "            w.append(w_new)\n",
    "        return w"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data to train data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate(([X1], [X2], [X3], [X4], [X5], [X6], [X7]), axis = 0)\n",
    "data = np.concatenate((np.ones((1, data.shape[1])), data), axis = 0)\n",
    "\n",
    "train_data = np.array([value[:350] for value in data])\n",
    "train_label = [1 if Yt[index] >= 0.75 else 0 for index in range(350)]\n",
    "test_data = np.array([value[350:] for value in data])\n",
    "test_label = [1 if Yt[index] >= 0.75 else 0 for index in range(350, 400)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate w_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.12890365]\n",
      " [-0.31576246]\n",
      " [-0.16058308]\n",
      " [ 1.83664662]\n",
      " [ 0.68157126]\n",
      " [ 0.77421802]\n",
      " [-0.76191388]\n",
      " [ 0.93698383]]\n"
     ]
    }
   ],
   "source": [
    "eta = 0.05\n",
    "d = train_data.shape[0]\n",
    "w_init = np.random.randn(d, 1) # initialize parameters w = w_init\n",
    "# call logistic_sigmoid_regression procedure\n",
    "w = logistic_sigmoid_regression(train_data, train_label, w_init, eta)\n",
    "# print out the parameter\n",
    "w_best = w[-1]\n",
    "print(w_best)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# percentages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict: \n",
      " [1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "predict = np.array(sigmoid(np.dot(w[-1].T, train_data)))\n",
    "result_predict = [1 if value >= 0.5 else 0 for value in predict[0]]\n",
    "print(\"predict: \\n\", result_predict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict test data: \n",
      " [1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1]\n",
      "accuracy score 0.8\n",
      "recall score 0.9090909090909091\n",
      "precision score 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def predicts(w_best, x):\n",
    "    x = np.array(x)\n",
    "    percentage = sigmoid(np.dot(w_best.T, x))\n",
    "    \n",
    "    result = [0]*percentage.shape[1]\n",
    "    for i in range(0, percentage.shape[1]):\n",
    "        if percentage[0][i] > 0.75:\n",
    "            result[i] = 1\n",
    "        else:\n",
    "            result[i] = 0\n",
    "    return result\n",
    "\n",
    "y_pre = predicts(w_best, test_data)\n",
    "print(\"Predict test data: \\n\", y_pre)\n",
    "print(\"accuracy score\", accuracy_score(test_label, y_pre))\n",
    "print(\"recall score\", recall_score(test_label, y_pre))\n",
    "print(\"precision score\", precision_score(test_label, y_pre))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84fd2673a0f847bf80637898000f9b4175f2ffd476d5f31b41a838c2acdb5b76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
