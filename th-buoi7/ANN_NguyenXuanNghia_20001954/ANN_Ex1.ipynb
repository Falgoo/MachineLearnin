{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import gzip\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set names to the paths because they're too long\n",
    "data_path = \"C:\\\\Users\\\\LENOVO\\Downloads\\\\\"\n",
    "# train path\n",
    "train_images_path = os.path.join(data_path, 'train-images-idx3-ubyte.gz')\n",
    "train_labels_path = os.path.join(data_path, 'train-labels-idx1-ubyte.gz')\n",
    "# test path\n",
    "test_images_path = os.path.join(data_path, 't10k-images-idx3-ubyte.gz')\n",
    "test_labels_path = os.path.join(data_path, 't10k-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_data(images_path, labels_path, num_images\n",
    ", shuffle=False, _is=True, image_size=28):\n",
    "    \"\"\"\n",
    "    This shuffle param is active when .gz is downloaded at:\n",
    "    - 'http://yann.lecun.com/exdb/mnist/'\n",
    "    - This function return random num_images in 60000 or 10000\n",
    "    \"\"\"\n",
    "    # read data\n",
    "    # open file training to read training data\n",
    "    f_images = gzip.open(images_path,'r')\n",
    "    # skip 16 first bytes because these are not data, only header infor\n",
    "    f_images.read(16)\n",
    "    # general: read num_images data samples if this parameter is set;\n",
    "    # if not, read all (60000 training or 10000 test)\n",
    "    real_num = num_images if not shuffle else (60000 if _is else 10000)\n",
    "    # read all data to buf_images (28x28xreal_num)\n",
    "    buf_images = f_images.read(image_size * image_size * real_num)\n",
    "    # images\n",
    "    images = np.frombuffer(buf_images, dtype=np.uint8).astype(np.float32)\n",
    "    images = images.reshape(real_num, image_size, image_size,)\n",
    "    # Read labels\n",
    "    f_labels = gzip.open(labels_path,'r')\n",
    "    f_labels.read(8)\n",
    "    labels = np.zeros((real_num)).astype(np.int64)\n",
    "    # rearrange to correspond the images and labels\n",
    "    for i in range(0, real_num):\n",
    "        buf_labels = f_labels.read(1)\n",
    "        labels[i] = np.frombuffer(buf_labels, dtype=np.uint8).astype(np.int64)\n",
    "    # shuffle to get random images data\n",
    "    if shuffle is True:\n",
    "        rand_id = np.random.randint(real_num, size=num_images)\n",
    "        images = images[rand_id, :]\n",
    "        labels = labels[rand_id,]\n",
    "    # change images data to type of vector 28x28 dimentional\n",
    "    images = images.reshape(num_images, image_size * image_size)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3500)\n"
     ]
    }
   ],
   "source": [
    "images, labels = get_mnist_data(train_images_path, train_labels_path, 5000, shuffle=True)\n",
    "images = StandardScaler().fit_transform(images)\n",
    "pca = PCA(n_components= 100)\n",
    "images_transform = pca.fit_transform(images)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(images_transform, labels, test_size=0.3, random_state=25)\n",
    "X_train = X_train.T\n",
    "X_test = X_test.T\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAENCAYAAABTviwWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAY40lEQVR4nO3df3DU9Z3H8Vd2QzYhbIIEEolJSPSsKEFFAg7Gq7WmeoittnNenYlXih72NBQoM62kHjqWgeic4+D5A5QZgbmCaOeaqzpVj4sDlgryS6joCdigRiEBTswGAptk93N/dEwvLYF84fPZzXf3+Zj5/sFO9rXvWTbvvPLdzW6GMcYIAADAgkCyBwAAAKmDYgEAAKyhWAAAAGsoFgAAwBqKBQAAsIZiAQAArKFYAAAAaygWAADAmsxE32A8HteBAwcUDoeVkZGR6JsH0p4xRh0dHSouLlYg4I/fLdgbQPINdHckvFgcOHBApaWlib5ZAH+hpaVFJSUlyR5jQNgbwOBxpt2R8GIRDoclSdfqZmVqiPX8pR9ssp4pSTf+7p+d5EpS6flfOMmNvDLaSa4knbyuw1l2MOjmXeaLnslykitJVY++6yT3P387xXpmPHpSHz+2sPd70Q++mvXK7/6LgkOyreePvrvZeqYk/XvFeie5knRF411Ocos2ufuUh8MT3J0hu+jfPnKS+8k/XewkV5J6vtbpJDf3naFOcmNdJ/Xhyl+ccXckvFh8dRozU0OUmWG/WITDbh64gRz7y+wrmbkhJ7nBLHczB4d2u8sOxp3kZma6uZ8lKTTM/mNZkoLZ7v4P/fSUwlezBodkOykWQ3LdlM48R/tIkgKOHhuZQ9wVi0C2u/sjM+Dm/zAYcvc9GB/qZte53P3SmXeHP55gBQAAvkCxAAAA1lAsAACANRQLAABgzVkVi6efflrl5eXKzs7W1VdfrS1bttieC0AKYncAqc9zsXjxxRc1b948PfTQQ9qxY4euuOIK3XTTTTp06JCL+QCkCHYHkB48F4vHH39cM2fO1IwZM3TZZZdp2bJlGjp0qJ5//nkX8wFIEewOID14KhZdXV3avn27ampq/hwQCKimpkabNp36jami0agikUifA0B68bo72BuAf3kqFkeOHFEsFlNRUVGfy4uKitTa2nrK6zQ0NCg/P7/34G15gfTjdXewNwD/cv5XIfX19Wpvb+89WlpaXN8kAJ9jbwD+5ektvUeOHKlgMKi2trY+l7e1ten8888/5XVCoZBCIXdvpQxg8PO6O9gbgH95OmORlZWliRMnqqmpqfeyeDyupqYmTZli/8OSAKQGdgeQPjx/CNm8efM0ffp0VVVVafLkyVqyZImOHz+uGTNmuJgPQIpgdwDpwXOx+P73v6/Dhw/rwQcfVGtrq6688kq9/vrrf/WiLAD4/9gdQHo4q49NnzVrlmbNmmV7FgApjt0BpD4+KwQAAFhDsQAAANZQLAAAgDUUCwAAYM1ZvXjTho6/n6TMIdnWc393cr/1TElq/pa7D0q6v+1KJ7m/vTHXSa4kLRz3qrPspz653knuhf/q5rEhSW3RPCe50eJu65nxE/YzE2X4f+1RZkaW9dzO7aOsZ0rSVd+810muJH1tU7uT3I6/CTvJlaTijTFn2SeqLnSTe0GPk1xJKngzx0nul2PjTnLjJweWyxkLAABgDcUCAABYQ7EAAADWUCwAAIA1FAsAAGANxQIAAFhDsQAAANZQLAAAgDUUCwAAYA3FAgAAWEOxAAAA1lAsAACANRQLAABgDcUCAABYQ7EAAADWUCwAAIA1FAsAAGANxQIAAFhDsQAAANZQLAAAgDUUCwAAYE1msm7Y3PG/iueGrOf+Yvct1jMlaeV5R53kStL//LHYTXDQuMmV9B+HJzrLbv0yz0nuie4hTnIlqe2TEU5yJ4zbbz2z+3iXPrOemhit/3CpglnZ1nML3j9pPVOSOsqdxEqS8j7OdZKb0xp1kitJsaHufuT05Lj5PTnvQ4c/JjPc7OiSN2NOcnu6Y/pkAF/HGQsAAGANxQIAAFhDsQAAANZQLAAAgDUUCwAAYA3FAgAAWEOxAAAA1ngqFg0NDZo0aZLC4bAKCwt12223ac+ePa5mA5Ai2B1A+vBULDZs2KC6ujpt3rxZ69atU3d3t2688UYdP37c1XwAUgC7A0gfnt5S7PXXX+/z75UrV6qwsFDbt2/X17/+dauDAUgd7A4gfZzTe5W2t7dLkkaM6P/tjKPRqKLRP79FbCQSOZebBJACzrQ72BuAf531izfj8bjmzp2r6upqVVZW9vt1DQ0Nys/P7z1KS0vP9iYBpICB7A72BuBfZ10s6urqtHv3bq1du/a0X1dfX6/29vbeo6Wl5WxvEkAKGMjuYG8A/nVWT4XMmjVLr776qt566y2VlJSc9mtDoZBCIfufYgrAfwa6O9gbgH95KhbGGP34xz9WY2Oj1q9fr4qKCldzAUgh7A4gfXgqFnV1dVqzZo1+85vfKBwOq7W1VZKUn5+vnJwcJwMC8D92B5A+PL3GYunSpWpvb9c3vvENjR49uvd48cUXXc0HIAWwO4D04fmpEADwit0BpA8+KwQAAFhDsQAAANZQLAAAgDUUCwAAYM05fVbIuWjfPkrB7GzruZd+c5/1TEna2VzmJFeSFMtwEps74oSTXEnaH+n/82HOVffHw5zkfvfvNjvJlaRnm7/pJLfHBH2RmSiBbqNAhv0Xgp4sGGI9U5Iu2NDjJFeS2i90M/Po9e4+l6Vz9HBn2cPfdvPurKEvipzkStKJwiw3uQVufrTHugaWyxkLAABgDcUCAABYQ7EAAADWUCwAAIA1FAsAAGANxQIAAFhDsQAAANZQLAAAgDUUCwAAYA3FAgAAWEOxAAAA1lAsAACANRQLAABgDcUCAABYQ7EAAADWUCwAAIA1FAsAAGANxQIAAFhDsQAAANZQLAAAgDUUCwAAYE1msm74xqlbFRo2xHru79sutJ4pSQoYN7mSqsfvc5L73ZE7nORKUv2O25xll1xx0EnuczuvdZIrSYGTGU5yD3bkWc+MdUatZybKyF0dygx2W889NibXeqYkmYCbx4UkZUXc7KSD1xU4yZWkvJYeZ9k9pSOd5GZ2uPt+CTvK/nTqcCe5sejAHs+csQAAANZQLAAAgDUUCwAAYA3FAgAAWEOxAAAA1lAsAACANRQLAABgzTkVi0ceeUQZGRmaO3eupXEApDr2BpDazrpYbN26Vc8++6wuv/xym/MASGHsDSD1nVWxOHbsmGpra7V8+XKdd955tmcCkILYG0B6OKtiUVdXp2nTpqmmpuaMXxuNRhWJRPocANIPewNID54/K2Tt2rXasWOHtm7dOqCvb2ho0MMPP+x5MACpg70BpA9PZyxaWlo0Z84crV69WtnZ2QO6Tn19vdrb23uPlpaWsxoUgD+xN4D04umMxfbt23Xo0CFdddVVvZfFYjG99dZbeuqppxSNRhUMBvtcJxQKKRQK2ZkWgO+wN4D04qlY3HDDDXrvvff6XDZjxgyNHTtW999//18tBwBgbwDpxVOxCIfDqqys7HNZbm6uCgoK/upyAJDYG0C64Z03AQCANZ7/KuQvrV+/3sIYANIJewNIXZyxAAAA1lAsAACANRQLAABgDcUCAABYc84v3jxbr22oUmCA78LnRawoaj1TkkaO7HCSK0lfduU4yX1g561OciWpuny/s+yPO0a4CT7i7g2X/vFbbznJ3XOsyHpmd1aXdllPTYzWKXkKhuzvjawvjfVMSRq+74STXEnKaYs5yW2bFHaSK0lyczdLkrqHDXGSGy/w3xu1jfpDt5Pcnu5u7RvA13HGAgAAWEOxAAAA1lAsAACANRQLAABgDcUCAABYQ7EAAADWUCwAAIA1FAsAAGANxQIAAFhDsQAAANZQLAAAgDUUCwAAYA3FAgAAWEOxAAAA1lAsAACANRQLAABgDcUCAABYQ7EAAADWUCwAAIA1FAsAAGANxQIAAFhDsQAAANZkJuuGe3JjCuTErOeOGf2F9UxJys7sdpIrSWW5R53kvv9liZNcSXo/93xn2UcO5znJHX3pISe5kvTyp5VOcjtPhqxnxjpPWs9MlPCnMWUOsb83sg9HrWdKUmdxtpNcSTp+vpvfC0NfGie5kqQMd9HdeW5+nPWE3A2d98JmJ7ndNROd5AZ64gP7Oie3DgAA0hLFAgAAWEOxAAAA1lAsAACANRQLAABgDcUCAABY47lYfP7557rzzjtVUFCgnJwcjR8/Xtu2bXMxG4AUwu4A0oOnP/w9evSoqqurdf311+u1117TqFGjtG/fPp133nmu5gOQAtgdQPrwVCweffRRlZaWasWKFb2XVVRUWB8KQGphdwDpw9NTIS+//LKqqqp0++23q7CwUBMmTNDy5ctPe51oNKpIJNLnAJBevO4O9gbgX56KRXNzs5YuXaqLL75Yb7zxhu69917Nnj1bq1at6vc6DQ0Nys/P7z1KS0vPeWgA/uJ1d7A3AP/yVCzi8biuuuoqLV68WBMmTNA999yjmTNnatmyZf1ep76+Xu3t7b1HS0vLOQ8NwF+87g72BuBfnorF6NGjddlll/W57NJLL9Wnn37a73VCoZDy8vL6HADSi9fdwd4A/MtTsaiurtaePXv6XLZ3716NGTPG6lAAUgu7A0gfnorFT37yE23evFmLFy/WRx99pDVr1ui5555TXV2dq/kApAB2B5A+PBWLSZMmqbGxUS+88IIqKyu1cOFCLVmyRLW1ta7mA5AC2B1A+vD0PhaSdMstt+iWW25xMQuAFMbuANIDnxUCAACsoVgAAABrKBYAAMAaigUAALDG84s3bZl1bZOyh9m/+Sd2XW89U5LiPe462LHCkJPcQGfQSa4kjcjpdJZ9PJzlJPdgq7tP0jRdbh4foeEnrWcaYz0yYfL+0KrMgP3vl9iofOuZktSVm+EkV5JCX7r5j8xt7XaSK0mxkLs9mtkZd5Ib6HL3f3jovmuc5Oa2xZzk9nQP7Gc2ZywAAIA1FAsAAGANxQIAAFhDsQAAANZQLAAAgDUUCwAAYA3FAgAAWEOxAAAA1lAsAACANRQLAABgDcUCAABYQ7EAAADWUCwAAIA1FAsAAGANxQIAAFhDsQAAANZQLAAAgDUUCwAAYA3FAgAAWEOxAAAA1lAsAACANRQLAABgTWaybnjZe3+rwNBs67mZmTHrmZJUVf6xk1xJ2vZZqZPcKZM/dJIrSdv++1Jn2V35xknutZM/cJIrSaOzI05yX9peZT0zfsLN/ZsIsYKwMoL290aw9aj1TEnKuSDHSa4kdeW6+b3w8JVZTnIlKf+PbvazJB0vDDrJDX/W7SRXkoYddHN/nChw89iIdQ0slzMWAADAGooFAACwhmIBAACsoVgAAABrKBYAAMAaigUAALDGU7GIxWJasGCBKioqlJOTo4suukgLFy6UMf798zUA7rE7gPTh6X0sHn30US1dulSrVq3SuHHjtG3bNs2YMUP5+fmaPXu2qxkB+By7A0gfnorF22+/rVtvvVXTpk2TJJWXl+uFF17Qli1bnAwHIDWwO4D04empkGuuuUZNTU3au3evJGnXrl3auHGjpk6d2u91otGoIpFInwNAevG6O9gbgH95OmMxf/58RSIRjR07VsFgULFYTIsWLVJtbW2/12loaNDDDz98zoMC8C+vu4O9AfiXpzMWL730klavXq01a9Zox44dWrVqlR577DGtWrWq3+vU19ervb2992hpaTnnoQH4i9fdwd4A/MvTGYuf/vSnmj9/vu644w5J0vjx4/XJJ5+ooaFB06dPP+V1QqGQQqHQuU8KwLe87g72BuBfns5YdHZ2KhDoe5VgMKh4PG51KACphd0BpA9PZyy+/e1va9GiRSorK9O4ceP07rvv6vHHH9ddd93laj4AKYDdAaQPT8XiySef1IIFC3Tffffp0KFDKi4u1o9+9CM9+OCDruYDkALYHUD68FQswuGwlixZoiVLljgaB0AqYncA6YPPCgEAANZQLAAAgDUUCwAAYA3FAgAAWOPpxZs2xXoCMt32e03JqKPWMyVpzxeFTnIlqbpsv5Pc339a4SRXkrrKo86yg5lu3ttg62djnORK0rcqPnSSO/WK3dYzu451aYX11MQ4OTJHmUOyrecevzxsPVOSsjrcvU9HZ5Gb3wvPf7vTSa4kHb0kx1n2yZEZTnLzPzZOciWpe6ibmeUodqC5nLEAAADWUCwAAIA1FAsAAGANxQIAAFhDsQAAANZQLAAAgDUUCwAAYA3FAgAAWEOxAAAA1lAsAACANRQLAABgDcUCAABYQ7EAAADWUCwAAIA1FAsAAGANxQIAAFhDsQAAANZQLAAAgDUUCwAAYA3FAgAAWEOxAAAA1mQm+gaNMZKk+Imok/ye425yY11OYiVJXcfchMc6TzrJlaR4NOYsOyMYd5IbG+Ju5q5j3U5ye4z9mbuO/2nWr74X/eCrWXt63DymY11uVmFPt5vHsiTFokEnua7uY0mKdWW4y466ye7pcfMzRZJiXW52UizTzX0R6/rTY+NMuyPDJHi7fPbZZyotLU3kTQI4hZaWFpWUlCR7jAFhbwCDx5l2R8KLRTwe14EDBxQOh5WRcfpWFYlEVFpaqpaWFuXl5SVownPDzInBzGfPGKOOjg4VFxcrEPDHs6Gpvjckf87NzIkxWGYe6O5I+FMhgUDA829JeXl5vnkAfIWZE4OZz05+fn5Sb9+rdNkbkj/nZubEGAwzD2R3+OPXFQAA4AsUCwAAYM2gLhahUEgPPfSQQqFQskcZMGZODGZGf/x6P/txbmZODL/NnPAXbwIAgNQ1qM9YAAAAf6FYAAAAaygWAADAGooFAACwZtAWi6efflrl5eXKzs7W1VdfrS1btiR7pNNqaGjQpEmTFA6HVVhYqNtuu0179uxJ9lgD9sgjjygjI0Nz585N9ihn9Pnnn+vOO+9UQUGBcnJyNH78eG3bti3ZY/UrFotpwYIFqqioUE5Oji666CItXLjQV5/V4Sd+2h1+3xuSf3YHeyOBzCC0du1ak5WVZZ5//nnz/vvvm5kzZ5rhw4ebtra2ZI/Wr5tuusmsWLHC7N692+zcudPcfPPNpqyszBw7dizZo53Rli1bTHl5ubn88svNnDlzkj3OaX3xxRdmzJgx5oc//KF55513THNzs3njjTfMRx99lOzR+rVo0SJTUFBgXn31VbN//37zq1/9ygwbNsw88cQTyR4t5fhtd/h5bxjjn93B3kisQVksJk+ebOrq6nr/HYvFTHFxsWloaEjiVN4cOnTISDIbNmxI9iin1dHRYS6++GKzbt06c9111w3q5WCMMffff7+59tprkz2GJ9OmTTN33XVXn8u+973vmdra2iRNlLr8vjv8sjeM8dfuYG8k1qB7KqSrq0vbt29XTU1N72WBQEA1NTXatGlTEifzpr29XZI0YsSIJE9yenV1dZo2bVqf+3swe/nll1VVVaXbb79dhYWFmjBhgpYvX57ssU7rmmuuUVNTk/bu3StJ2rVrlzZu3KipU6cmebLUkgq7wy97Q/LX7mBvJFbCP4TsTI4cOaJYLKaioqI+lxcVFenDDz9M0lTexONxzZ07V9XV1aqsrEz2OP1au3atduzYoa1btyZ7lAFrbm7W0qVLNW/ePP385z/X1q1bNXv2bGVlZWn69OnJHu+U5s+fr0gkorFjxyoYDCoWi2nRokWqra1N9mgpxe+7wy97Q/Lf7mBvJNagKxapoK6uTrt379bGjRuTPUq/WlpaNGfOHK1bt07Z2dnJHmfA4vG4qqqqtHjxYknShAkTtHv3bi1btmzQLoiXXnpJq1ev1po1azRu3Djt3LlTc+fOVXFx8aCdGYnnh70h+XN3sDcSLNnPxfylaDRqgsGgaWxs7HP5D37wA/Od73wnOUN5UFdXZ0pKSkxzc3OyRzmtxsZGI8kEg8HeQ5LJyMgwwWDQ9PT0JHvEUyorKzN33313n8ueeeYZU1xcnKSJzqykpMQ89dRTfS5buHChueSSS5I0UWry8+7wy94wxp+7g72RWIPuNRZZWVmaOHGimpqaei+Lx+NqamrSlClTkjjZ6RljNGvWLDU2NurNN99URUVFskc6rRtuuEHvvfeedu7c2XtUVVWptrZWO3fuVDAYTPaIp1RdXf1Xf463d+9ejRkzJkkTnVlnZ6cCgb7fasFgUPF4PEkTpSY/7g6/7Q3Jn7uDvZFgyW42p7J27VoTCoXMypUrzQcffGDuueceM3z4cNPa2prs0fp17733mvz8fLN+/Xpz8ODB3qOzszPZow3YYH9ltzF/+vO2zMxMs2jRIrNv3z6zevVqM3ToUPPLX/4y2aP1a/r06eaCCy7o/bOxX//612bkyJHmZz/7WbJHSzl+2x2psDeMGfy7g72RWIOyWBhjzJNPPmnKyspMVlaWmTx5stm8eXOyRzotSac8VqxYkezRBmywL4evvPLKK6aystKEQiEzduxY89xzzyV7pNOKRCJmzpw5pqyszGRnZ5sLL7zQPPDAAyYajSZ7tJTkp92RCnvDGH/sDvZG4vCx6QAAwJpB9xoLAADgXxQLAABgDcUCAABYQ7EAAADWUCwAAIA1FAsAAGANxQIAAFhDsQAAANZQLAAAgDUUCwAAYA3FAgAAWEOxAAAA1vwfv2PeB4wa1EwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for display and test digit :D\n",
    "def get_image(image):\n",
    "    return image.reshape(10, 10)\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "index = random.randint(0, 99)\n",
    "train_image = np.asarray(get_image(X_train[:, index])).squeeze()\n",
    "test_image = np.asarray(get_image(X_test[:, index])).squeeze()\n",
    "plt.figure()\n",
    "#subplot(r,c) provide the no. of rows and columns\n",
    "f, axarr = plt.subplots(1, 2)\n",
    "# use the created array to output your multiple images. In this case I have stacked 4 images vertically\n",
    "axarr[0].imshow(train_image)\n",
    "axarr[1].imshow(test_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(V):\n",
    "    e_V = np.exp(V - np.max(V, axis = 0, keepdims = True))\n",
    "    Z = e_V / e_V.sum(axis = 0)\n",
    "    return Z\n",
    "\n",
    "# cost or loss function\n",
    "def cost(Y, Yhat):\n",
    "    return -np.sum(Y*np.log(Yhat))/Y.shape[1]\n",
    "\n",
    "## One-hot coding\n",
    "from scipy import sparse\n",
    "def convert_labels(y, C = 100):\n",
    "    Y = sparse.coo_matrix((np.ones_like(y),\n",
    "    (y, np.arange(len(y)))), shape = (C, len(y))).toarray()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "d0 = 100\n",
    "d1 = h = 100 # size of hidden layer\n",
    "\n",
    "d2 = C = 10\n",
    "# initialize parameters randomly\n",
    "W1 = 0.01*np.random.randn(d0, d1)\n",
    "b1 = np.zeros((d1, 1))\n",
    "W2 = 0.01*np.random.randn(d1, d2)\n",
    "b2 = np.zeros((d2, 1))\n",
    "\n",
    "Y = convert_labels(Y_train, C)\n",
    "N = X_train.shape[1]\n",
    "eta = 1 # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0, loss: 2.303890\n",
      "iter 1000, loss: 0.001503\n",
      "iter 2000, loss: 0.000591\n",
      "iter 3000, loss: 0.000352\n",
      "iter 4000, loss: 0.000246\n",
      "iter 5000, loss: 0.000188\n",
      "iter 6000, loss: 0.000150\n",
      "iter 7000, loss: 0.000125\n",
      "iter 8000, loss: 0.000106\n",
      "iter 9000, loss: 0.000093\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    ## Feedforward\n",
    "    Z1 = np.dot(W1.T, X_train) + b1\n",
    "    A1 = np.maximum(Z1, 0)\n",
    "    Z2 = np.dot(W2.T, A1) + b2\n",
    "    Yhat = softmax(Z2)\n",
    "\n",
    "    # print loss after each 1000 iterations\n",
    "    if i %1000 == 0:\n",
    "        # compute the loss: average cross-entropy loss\n",
    "        loss = cost(Y, Yhat)\n",
    "        print(\"iter %d, loss: %f\" %(i, loss))\n",
    "\n",
    "    # backpropagation\n",
    "    E2 = (Yhat - Y )/N\n",
    "    dW2 = np.dot(A1, E2.T)\n",
    "    db2 = np.sum(E2, axis = 1, keepdims = True)\n",
    "    E1 = np.dot(W2, E2)\n",
    "    E1[Z1 <= 0] = 0 # gradient of ReLU\n",
    "    dW1 = np.dot(X_train, E1.T)\n",
    "    db1 = np.sum(E1, axis = 1, keepdims = True)\n",
    "    # Gradient Descent update\n",
    "    W1 += -eta*dW1\n",
    "    b1 += -eta*db1\n",
    "    W2 += -eta*dW2\n",
    "    b2 += -eta*db2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 100.00 %\n"
     ]
    }
   ],
   "source": [
    "Z1 = np.dot(W1.T, X_train) + b1\n",
    "A1 = np.maximum(Z1, 0)\n",
    "Z2 = np.dot(W2.T, A1) + b2\n",
    "predicted_class = np.argmax(Z2, axis=0)\n",
    "acc = 100*np.mean(predicted_class == Y_train)\n",
    "print('training accuracy: %.2f %%' % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy: 93.00 %\n"
     ]
    }
   ],
   "source": [
    "Z1 = np.dot(W1.T, X_test) + b1\n",
    "A1 = np.maximum(Z1, 0)\n",
    "Z2 = np.dot(W2.T, A1) + b2\n",
    "predicted_class = np.argmax(Z2, axis=0)\n",
    "acc = 100*np.mean(predicted_class == Y_test)\n",
    "print('testing accuracy: %.2f %%' % (acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84fd2673a0f847bf80637898000f9b4175f2ffd476d5f31b41a838c2acdb5b76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
