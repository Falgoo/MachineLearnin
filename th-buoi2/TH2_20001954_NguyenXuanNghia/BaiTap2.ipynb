{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data and split to train data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " test-data :  [[ 49.    24.   140.     4.3    5.5 ]\n",
      " [ 36.    23.   140.     4.3    4.2 ]\n",
      " [ 74.    21.   140.    17.     3.3 ]\n",
      " [ 53.    21.   140.     5.6    5.9 ]\n",
      " [ 56.    19.   140.     4.1    4.73]\n",
      " [ 60.    20.   160.     4.9    3.  ]\n",
      " [ 83.    21.   120.     7.9    5.88]\n",
      " [ 68.    23.   130.     4.     5.39]\n",
      " [ 69.    19.   100.     4.4    6.15]\n",
      " [ 31.    21.   120.     4.1    3.94]\n",
      " [ 34.    21.   140.     6.7    3.83]\n",
      " [ 41.    20.   120.     2.7    4.93]\n",
      " [ 72.    22.   160.     6.4    7.  ]\n",
      " [ 54.    22.   170.     6.2    8.18]\n",
      " [ 54.    28.   150.     4.2    8.16]\n",
      " [ 55.    24.   160.     5.     7.2 ]\n",
      " [ 76.    15.   140.     3.1    5.24]\n",
      " [ 70.    25.   180.     4.     4.4 ]\n",
      " [ 85.    21.   160.     5.2    5.2 ]\n",
      " [ 87.    22.   130.     9.     5.2 ]]\n",
      "\n",
      " test-label :  [0.8  0.7  1.   0.8  0.89 0.6  1.5  0.7  1.1  0.81 0.7  0.71 2.7  1.13\n",
      " 1.7  0.9  1.16 1.   0.97 2.3 ]\n",
      "\n",
      " train-data :  [[ 56.    21.   160.    14.     6.  ]\n",
      " [ 76.    18.   150.    12.     4.97]\n",
      " [ 63.    16.   160.     4.4    6.39]\n",
      " [ 78.    20.   100.     4.     7.  ]\n",
      " [ 87.    20.   110.     4.6    4.1 ]\n",
      " [ 76.    19.   150.     4.6    2.74]\n",
      " [ 55.    31.   160.     5.5    4.6 ]\n",
      " [ 74.    22.   100.     6.8    5.04]\n",
      " [ 81.    21.   120.     5.8    4.75]\n",
      " [ 77.    24.   160.     5.4    6.94]\n",
      " [ 29.    20.   120.     3.8    4.84]\n",
      " [ 71.    22.   160.     3.3    6.63]\n",
      " [ 77.    21.   160.     5.1    4.93]\n",
      " [ 59.    18.   150.     6.     4.55]\n",
      " [ 58.    27.   130.     6.9    6.7 ]\n",
      " [ 34.    19.   130.     4.5    3.2 ]\n",
      " [ 74.    22.   100.    10.6    4.3 ]\n",
      " [ 61.    19.   170.    18.     6.8 ]\n",
      " [ 53.    20.   130.    25.     5.5 ]\n",
      " [ 65.    28.   140.     6.5    6.8 ]\n",
      " [ 80.    19.   160.     4.8    5.74]\n",
      " [ 71.    25.   160.     6.2    6.9 ]\n",
      " [ 90.    24.   160.     4.7    7.  ]\n",
      " [ 44.    24.   120.     6.     3.4 ]\n",
      " [ 91.    27.   150.     6.1    4.92]\n",
      " [ 75.    22.   160.     6.2    6.08]\n",
      " [ 60.    24.   140.     4.7    6.25]\n",
      " [ 51.    22.   150.     4.8    5.4 ]\n",
      " [ 91.    29.   120.     4.2    6.54]\n",
      " [ 45.    24.   170.     4.9    3.91]\n",
      " [ 62.    24.   140.     5.4    5.3 ]\n",
      " [ 65.    19.   150.    12.     2.6 ]\n",
      " [ 70.    22.   160.     3.6    6.85]\n",
      " [ 56.    27.   150.     5.7    3.75]\n",
      " [ 51.    19.   120.     4.7    5.84]\n",
      " [ 75.    18.   140.    10.1    6.91]\n",
      " [ 58.    32.   160.     4.7    5.01]\n",
      " [ 61.    19.   160.     5.2    4.  ]\n",
      " [ 72.    18.   120.    22.2    4.88]\n",
      " [ 82.    25.    90.     8.2    4.2 ]\n",
      " [ 95.    24.   120.    11.     4.47]\n",
      " [ 56.    21.   160.     4.9    6.9 ]\n",
      " [ 36.    28.   130.     4.5    4.71]\n",
      " [ 67.    18.   100.     5.5    5.7 ]\n",
      " [ 64.    22.   130.     6.2    3.  ]\n",
      " [ 81.    22.   140.     5.     5.06]\n",
      " [ 46.    22.   160.     3.3    4.61]\n",
      " [ 56.    22.   150.     4.1    4.15]\n",
      " [ 60.    24.   140.     7.1    5.3 ]\n",
      " [ 35.    19.   120.     7.4    4.1 ]\n",
      " [ 55.    21.   160.     5.4    3.  ]\n",
      " [ 70.    20.   150.     6.2    2.57]\n",
      " [ 64.    23.   130.     5.7    6.78]\n",
      " [ 64.    19.   160.     5.9    5.62]\n",
      " [ 58.    27.   160.    26.     8.07]\n",
      " [ 73.    23.   140.     5.6    3.  ]\n",
      " [ 41.    24.   110.    10.     3.31]\n",
      " [ 74.    23.   100.     5.3    4.73]\n",
      " [ 21.    23.   160.     5.     4.  ]\n",
      " [ 67.    25.   150.     3.5    3.6 ]\n",
      " [ 57.    23.   140.     6.4    5.3 ]\n",
      " [ 69.    21.   120.     7.6    6.  ]\n",
      " [ 53.    34.   140.     8.1    6.49]\n",
      " [ 58.    23.   160.     9.     7.  ]\n",
      " [ 54.    29.   130.     6.4    7.48]\n",
      " [ 49.    17.   130.     6.3    5.19]\n",
      " [ 59.    22.   140.     7.     3.  ]\n",
      " [ 65.    23.   150.     5.9    6.7 ]\n",
      " [ 42.    22.   150.     3.9    7.  ]\n",
      " [ 75.    24.   100.     6.4    6.6 ]\n",
      " [ 72.    21.   140.    11.     5.75]\n",
      " [ 82.    24.   190.    18.     4.7 ]\n",
      " [ 70.    18.   160.     3.3    4.61]\n",
      " [ 42.    24.   160.     6.     6.3 ]\n",
      " [ 32.    19.   140.     4.     2.  ]\n",
      " [ 61.    21.   140.     5.2    2.5 ]\n",
      " [ 60.    26.   130.    11.3    4.79]\n",
      " [ 76.    19.   160.     5.1    5.31]\n",
      " [ 78.    27.   120.     4.9    3.8 ]\n",
      " [ 71.    26.   150.     6.6    7.13]]\n",
      "\n",
      " train-label [1.95 1.33 0.83 2.   1.3  1.16 1.   1.   0.8  1.6  0.65 1.   0.97 0.73\n",
      " 1.1  1.1  1.1  0.8  0.99 1.   1.13 1.   1.7  0.9  0.89 0.8  0.81 1.2\n",
      " 0.82 0.89 1.19 0.97 0.97 0.97 0.88 0.97 0.9  0.89 0.8  1.13 1.2  0.9\n",
      " 0.81 0.8  0.74 2.66 0.89 0.79 0.8  0.56 0.8  1.2  0.82 0.9  1.   1.15\n",
      " 1.16 0.97 0.8  1.67 1.06 1.1  0.8  1.7  0.99 1.16 0.62 1.   0.82 1.\n",
      " 1.7  2.3  0.89 0.97 0.7  1.1  1.01 1.15 0.92 1.1 ]\n"
     ]
    }
   ],
   "source": [
    "def read_data(path):\n",
    "    with open(path) as f:\n",
    "        content = f.readlines()\n",
    "    content = [x.strip() for x in content]\n",
    "\n",
    "    data = [[float(y) for y in x.split(' ')] for x in content if x[0] != \"I\"]\n",
    "\n",
    "    # remove ID attribute out of data\n",
    "    data = [ele[1:] for ele in data]\n",
    "\n",
    "    train_data = data[:80]\n",
    "    train_label = [ele.pop() for ele in train_data]\n",
    "\n",
    "    test_data = data[80:]\n",
    "    test_label = [ele.pop() for ele in test_data]\n",
    "\n",
    "    train_data = np.asarray(train_data)\n",
    "    train_label = np.asarray(train_label)\n",
    "    test_data = np.asarray(test_data)\n",
    "    test_label = np.asarray(test_label)\n",
    "\n",
    "    return train_data, train_label, test_data, test_label\n",
    "\n",
    "path =\"./vidu4_lin_reg.txt\"\n",
    "train_data, train_label, test_data, test_label = read_data(path)\n",
    "\n",
    "print(\"\\n test-data : \",test_data)\n",
    "print(\"\\n test-label : \",test_label)\n",
    "print(\"\\n train-data : \",train_data)\n",
    "print(\"\\n train-label\",train_label)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qr_householder(A):\n",
    "    # Compute QR decomposition of A using Householder reflection\n",
    "    M = A.shape[0]\n",
    "    N = A.shape[1]\n",
    "\n",
    "    # set Q to the identity matrix\n",
    "    Q = np.identity(M)\n",
    "\n",
    "    # set R to zero matrix\n",
    "    R = np.copy(A)\n",
    "\n",
    "    for n in range(N):\n",
    "        # vector to transform\n",
    "        x = A[n:, n]\n",
    "        k = x.shape[0]\n",
    "\n",
    "        # compute ro=-sign(x0)||x||\n",
    "        ro = -np.sign(x[0]) * np.linalg.norm(x)\n",
    "\n",
    "        # compute the householder vector v\n",
    "        e = np.zeros(k)\n",
    "        e[0] = 1\n",
    "        v = (1 / (x[0] - ro)) * (x - (ro * e))\n",
    "\n",
    "    # apply v to each column of A to find R\n",
    "    for i in range(N):\n",
    "        R[n:, i] = R[n:, i] - (2 / (v@v)) * ((np.outer(v, v)) @ R[n:, i])\n",
    "\n",
    "    # apply v to each column of Q\n",
    "    for i in range(M):\n",
    "        Q[n:, i] = Q[n:, i] - (2 / (v@v)) * ((np.outer(v, v)) @ Q[n:, i])\n",
    "\n",
    "    return Q.transpose(), R"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(train_data, train_label):\n",
    "    x_bars = np.concatenate((np.ones((train_data.shape[0], 1)), train_data), axis=1)\n",
    "\n",
    "    Q, R = qr_householder(x_bars) # QR decomposition\n",
    "    R_pinv = np.linalg.pinv(R) # calculate inverse matrix of R\n",
    "    A = np.dot(R_pinv, Q.T) # apply formula\n",
    "\n",
    "    return np.dot(A, train_label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression coef:\n",
      "\n",
      "           Intercept: 0.04306436410330214\n",
      "                 Age: 0.00898919688929678\n",
      "         Cholesterol: -0.0004774242218528804\n",
      "             Glucose: 0.0026021798675557707\n",
      "                  HA: 0.008086342231978107\n",
      "                 BMI: 0.007085352341923775\n"
     ]
    }
   ],
   "source": [
    "w = linear_regression(train_data, train_label) # get result\n",
    "w = w.T.tolist()\n",
    "print(\"Regression coef:\\n\")\n",
    "line = ['Intercept', 'Age', 'Cholesterol', 'Glucose', 'HA', 'BMI']\n",
    "res = list(zip(line, w))\n",
    "for o in res:\n",
    "    print(\"{: >20}: {: >10}\".format(*o))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run program with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validate predict:\n",
      " [0.9101227212902697, 0.7845296279067635, 1.2233936873821376, 0.9608581673513565, 0.9683612308749348, 1.0500956057954387, 1.1969473567658557, 1.0521677963059988, 0.9936206987286872, 0.6850354344975742, 0.7842917235621115, 0.7710984473061301, 1.1974820427389565, 1.0684417447242467, 0.9972192105312192, 1.033807038520821, 1.1455820530106848, 1.1922858362001707, 1.292361781627831, 1.2625254556394154]\n",
      "\n",
      "Mean of error is:  0.30532598337436617\n",
      "Variance of error is:  0.1341770355526352\n"
     ]
    }
   ],
   "source": [
    "y_pre = [w[0]]*len(test_data)\n",
    "for val_index in range(0, len(test_data)):\n",
    "    for i in range(0,len(test_data[val_index])):\n",
    "        y_pre[val_index] += w[i+1]*test_data[val_index][i]\n",
    "\n",
    "error = np.abs(test_label - y_pre)\n",
    "mean = np.mean(error)\n",
    "variance = np.var(error)\n",
    "\n",
    "print(\"validate predict:\\n\",y_pre)\n",
    "print(\"\\nMean of error is: \", mean)\n",
    "print(\"Variance of error is: \", variance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84fd2673a0f847bf80637898000f9b4175f2ffd476d5f31b41a838c2acdb5b76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
